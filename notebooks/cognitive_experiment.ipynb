{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7wtXkgfW8yc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "diag = pd.read_csv(\"Diagnostic_Summary.csv\")\n",
        "mmse = pd.read_csv(\"MMSE.csv\")\n",
        "cdr = pd.read_csv(\"CDR.csv\")\n",
        "adas = pd.read_csv(\"ADAS.csv\")\n",
        "moca = pd.read_csv(\"MOCA.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "diag = pd.read_csv(\"Diagnostic_Summary.csv\")\n",
        "print(diag.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vx9d_JXjZNPH",
        "outputId": "c1f3ab0e-6cbb-42dd-9f0f-12b1608259da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['PHASE', 'PTID', 'RID', 'VISCODE', 'VISCODE2', 'EXAMDATE', 'DIAGNOSIS',\n",
            "       'DXNORM', 'DXNODEP', 'DXMCI', 'DXMDES', 'DXMPTR1', 'DXMPTR2', 'DXMPTR3',\n",
            "       'DXMPTR4', 'DXMPTR5', 'DXMPTR6', 'DXMDUE', 'DXMOTHET', 'DXDSEV',\n",
            "       'DXDDUE', 'DXAD', 'DXAPP', 'DXAPROB', 'DXAPOSS', 'DXPARK', 'DXPDES',\n",
            "       'DXPCOG', 'DXPATYP', 'DXDEP', 'DXOTHDEM', 'DXODES', 'DXCONFID', 'ID',\n",
            "       'SITEID', 'USERDATE', 'USERDATE2', 'DD_CRF_VERSION_LABEL',\n",
            "       'LANGUAGE_CODE', 'HAS_QC_ERROR', 'update_stamp'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(mmse.columns)  # For MMSE.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7Mej-4YaBfI",
        "outputId": "066d873e-dd66-41af-e096-f8d30db2e80c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['PHASE', 'PTID', 'RID', 'VISCODE', 'VISCODE2', 'VISDATE', 'DONE',\n",
            "       'NDREASON', 'SOURCE', 'MMDATE', 'MMYEAR', 'MMMONTH', 'MMDAY',\n",
            "       'MMSEASON', 'MMHOSPIT', 'MMFLOOR', 'MMCITY', 'MMAREA', 'MMSTATE',\n",
            "       'WORDLIST', 'WORD1', 'WORD2', 'WORD3', 'MMTRIALS', 'MMD', 'MML', 'MMR',\n",
            "       'MMO', 'MMW', 'MMLTR1', 'MMLTR2', 'MMLTR3', 'MMLTR4', 'MMLTR5',\n",
            "       'MMLTR6', 'MMLTR7', 'WORLDSCORE', 'WORD1DL', 'WORD2DL', 'WORD3DL',\n",
            "       'MMWATCH', 'MMPENCIL', 'MMREPEAT', 'MMHAND', 'MMFOLD', 'MMONFLR',\n",
            "       'MMREAD', 'MMWRITE', 'MMDRAW', 'MMSCORE', 'ID', 'SITEID', 'USERDATE',\n",
            "       'USERDATE2', 'DD_CRF_VERSION_LABEL', 'LANGUAGE_CODE', 'HAS_QC_ERROR',\n",
            "       'update_stamp'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(cdr.columns)   # For CDR.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GD2YXKvQaE23",
        "outputId": "344ce02e-2301-4e3e-c197-e886dbd29428"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['PHASE', 'PTID', 'RID', 'VISCODE', 'VISCODE2', 'VISDATE', 'CDSOURCE',\n",
            "       'CDVERSION', 'SPID', 'CDMEMORY', 'CDORIENT', 'CDJUDGE', 'CDCOMMUN',\n",
            "       'CDHOME', 'CDCARE', 'CDGLOBAL', 'CDRSB', 'ID', 'SITEID', 'USERDATE',\n",
            "       'USERDATE2', 'DD_CRF_VERSION_LABEL', 'LANGUAGE_CODE', 'HAS_QC_ERROR',\n",
            "       'update_stamp'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(adas.columns)  # For ADAS.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_kRf5rhaIcP",
        "outputId": "aa3ac1ee-229f-411e-ba71-9be4e79a140a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['PHASE', 'PTID', 'RID', 'VISCODE', 'VISCODE2', 'VISDATE', 'TOTSCORE',\n",
            "       'TOTAL13', 'ID', 'SITEID', 'USERDATE', 'USERDATE2',\n",
            "       'DD_CRF_VERSION_LABEL', 'LANGUAGE_CODE', 'HAS_QC_ERROR',\n",
            "       'update_stamp'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(moca.columns)  # For MOCA.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTAdVwBpaOOB",
        "outputId": "228f7197-ff13-4c7e-f19e-db0c429eebbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['PHASE', 'PTID', 'RID', 'VISCODE', 'VISCODE2', 'VISDATE', 'TRAILS',\n",
            "       'CUBE', 'CLOCKCON', 'CLOCKNO', 'CLOCKHAN', 'LION', 'RHINO', 'CAMEL',\n",
            "       'IMMT1W1', 'IMMT1W2', 'IMMT1W3', 'IMMT1W4', 'IMMT1W5', 'IMMT2W1',\n",
            "       'IMMT2W2', 'IMMT2W3', 'IMMT2W4', 'IMMT2W5', 'DIGFOR', 'DIGBACK',\n",
            "       'LETTERS', 'SERIAL1', 'SERIAL2', 'SERIAL3', 'SERIAL4', 'SERIAL5',\n",
            "       'REPEAT1', 'REPEAT2', 'FFLUENCY', 'ABSTRAN', 'ABSMEAS', 'DELW1',\n",
            "       'DELW2', 'DELW3', 'DELW4', 'DELW5', 'DATE', 'MONTH', 'YEAR', 'DAY',\n",
            "       'PLACE', 'CITY', 'MOCA', 'SOURCE', 'ID', 'SITEID', 'USERDATE',\n",
            "       'USERDATE2', 'DD_CRF_VERSION_LABEL', 'LANGUAGE_CODE', 'HAS_QC_ERROR',\n",
            "       'update_stamp'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "faq = pd.read_csv(\"FAQ.csv\")\n",
        "print(faq.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sebu5rYkwzRw",
        "outputId": "32c8dba6-25cb-4387-c13e-7802af5a767a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['PHASE', 'PTID', 'RID', 'VISCODE', 'VISCODE2', 'VISDATE', 'SOURCE',\n",
            "       'FAQFINAN', 'FAQFORM', 'FAQSHOP', 'FAQGAME', 'FAQBEVG', 'FAQMEAL',\n",
            "       'FAQEVENT', 'FAQTV', 'FAQREM', 'FAQTRAVL', 'FAQTOTAL', 'SPID', 'ID',\n",
            "       'SITEID', 'USERDATE', 'USERDATE2', 'DD_CRF_VERSION_LABEL',\n",
            "       'LANGUAGE_CODE', 'HAS_QC_ERROR', 'update_stamp'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "neuro = pd.read_csv(\"Neuropsychological_Battery.csv\")\n",
        "print(neuro.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkl4dm7jw7zA",
        "outputId": "32e24fcf-4a89-4e1a-f9f4-edb0ecb92d23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['PHASE', 'PTID', 'RID', 'VISCODE', 'VISCODE2', 'VISDATE', 'SOURCE',\n",
            "       'CLOCKCIRC', 'CLOCKSYM', 'CLOCKNUM', 'CLOCKHAND', 'CLOCKTIME',\n",
            "       'CLOCKSCOR', 'COPYCIRC', 'COPYSYM', 'COPYNUM', 'COPYHAND', 'COPYTIME',\n",
            "       'COPYSCOR', 'LMSTORY', 'LIMMTOTAL', 'LIMMEND', 'AVTOT1', 'AVERR1',\n",
            "       'AVTOT2', 'AVERR2', 'AVTOT3', 'AVERR3', 'AVTOT4', 'AVERR4', 'AVTOT5',\n",
            "       'AVERR5', 'AVTOT6', 'AVERR6', 'AVTOTB', 'AVERRB', 'AVENDED', 'DSPANFOR',\n",
            "       'DSPANFLTH', 'DSPANBAC', 'DSPANBLTH', 'CATANIMSC', 'CATANPERS',\n",
            "       'CATANINTR', 'CATVEGESC', 'CATVGPERS', 'CATVGINTR', 'TRAASCOR',\n",
            "       'TRAAERRCOM', 'TRAAERROM', 'TRABSCOR', 'TRABERRCOM', 'TRABERROM',\n",
            "       'DIGITSCOR', 'LDELBEGIN', 'LDELTOTAL', 'LDELCUE', 'BNTND', 'BNTSPONT',\n",
            "       'BNTSTIM', 'BNTCSTIM', 'BNTPHON', 'BNTCPHON', 'BNTTOTAL', 'AVDELBEGAN',\n",
            "       'AVDEL30MIN', 'AVDELERR1', 'AVDELTOT', 'AVDELERR2', 'ANARTERR',\n",
            "       'ANARTND', 'ANART', 'MINTSEMCUE', 'MINTTOTAL', 'MINTUNCUED', 'ID',\n",
            "       'SITEID', 'USERDATE', 'USERDATE2', 'DD_CRF_VERSION_LABEL',\n",
            "       'LANGUAGE_CODE', 'HAS_QC_ERROR', 'update_stamp'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2166302250.py:1: DtypeWarning: Columns (79,80) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  neuro = pd.read_csv(\"Neuropsychological_Battery.csv\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uw = pd.read_csv(\"UW_Neuropsych_Summary_Scores.csv\")\n",
        "print(uw.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QSRXsfWxJdc",
        "outputId": "2eaf2fc4-5d45-4e94-c392-283e9ca39bdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['PHASE', 'RID', 'VISCODE', 'VISCODE2', 'EXAMDATE', 'ADNI_MEM',\n",
            "       'ADNI_EF', 'ADNI_LAN', 'ADNI_VS', 'ADNI_EF2', 'update_stamp'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ecog = pd.read_csv(\"Everyday_Cognition_Study_Partner_Report.csv\")\n",
        "print(ecog.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEZkBKmxxbGe",
        "outputId": "c085f9b7-abff-41c0-c468-f581fe01db76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['PHASE', 'PTID', 'RID', 'VISCODE', 'VISCODE2', 'VISDATE', 'MEMORY1',\n",
            "       'MEMORY2', 'MEMORY3', 'MEMORY4', 'MEMORY5', 'MEMORY6', 'MEMORY7',\n",
            "       'MEMORY8', 'LANG1', 'LANG2', 'LANG3', 'LANG4', 'LANG5', 'LANG6',\n",
            "       'LANG7', 'LANG8', 'LANG9', 'VISSPAT1', 'VISSPAT2', 'VISSPAT3',\n",
            "       'VISSPAT4', 'VISSPAT5', 'VISSPAT6', 'VISSPAT7', 'VISSPAT8', 'PLAN1',\n",
            "       'PLAN2', 'PLAN3', 'PLAN4', 'PLAN5', 'ORGAN1', 'ORGAN2', 'ORGAN3',\n",
            "       'ORGAN4', 'ORGAN5', 'ORGAN6', 'DIVATT1', 'DIVATT2', 'DIVATT3',\n",
            "       'DIVATT4', 'SOURCE', 'EcogSPMem', 'EcogSPLang', 'EcogSPVisspat',\n",
            "       'EcogSPPlan', 'EcogSPOrgan', 'EcogSPDivatt', 'EcogSPTotal', 'ID',\n",
            "       'SITEID', 'USERDATE', 'USERDATE2', 'update_stamp'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# ==============================\n",
        "# 1Ô∏è‚É£ LOAD ALL CSV FILES\n",
        "# ==============================\n",
        "\n",
        "mmse = pd.read_csv(\"MMSE.csv\")\n",
        "cdr = pd.read_csv(\"CDR.csv\")\n",
        "adas = pd.read_csv(\"ADAS.csv\")\n",
        "moca = pd.read_csv(\"MOCA.csv\")\n",
        "diag = pd.read_csv(\"Diagnostic_Summary.csv\")\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# 2Ô∏è‚É£ KEEP ONLY REQUIRED COLUMNS\n",
        "# ==============================\n",
        "\n",
        "mmse = mmse[['RID', 'VISCODE', 'MMSCORE']]\n",
        "cdr = cdr[['RID', 'VISCODE', 'CDRSB']]\n",
        "adas = adas[['RID', 'VISCODE', 'TOTAL13']]\n",
        "moca = moca[['RID', 'VISCODE', 'MOCA']]\n",
        "diag = diag[['RID', 'VISCODE', 'DIAGNOSIS']]\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# 3Ô∏è‚É£ RENAME SCORE COLUMNS\n",
        "# ==============================\n",
        "\n",
        "mmse = mmse.rename(columns={'MMSCORE': 'MMSE'})\n",
        "cdr = cdr.rename(columns={'CDRSB': 'CDR'})\n",
        "adas = adas.rename(columns={'TOTAL13': 'ADAS13'})\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# 4Ô∏è‚É£ MERGE ALL FILES\n",
        "# ==============================\n",
        "\n",
        "merged = mmse.merge(cdr, on=['RID', 'VISCODE'], how='outer') \\\n",
        "             .merge(adas, on=['RID', 'VISCODE'], how='outer') \\\n",
        "             .merge(moca, on=['RID', 'VISCODE'], how='outer')\n",
        "\n",
        "final_data = merged.merge(diag, on=['RID', 'VISCODE'], how='left')\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# 5Ô∏è‚É£ CHECK FINAL DATA\n",
        "# ==============================\n",
        "\n",
        "print(final_data.head())\n",
        "print(\"Final shape:\", final_data.shape)\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# 6Ô∏è‚É£ (OPTIONAL) SAVE FINAL CSV\n",
        "# ==============================\n",
        "\n",
        "final_data.to_csv(\"Final_Merged_Data.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCYSjFyQbjHW",
        "outputId": "4c40411e-870f-4e9e-bdb6-1829d2755a22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   RID VISCODE  MMSE  CDR  ADAS13  MOCA  DIAGNOSIS\n",
            "0    1       f  28.0  NaN     NaN   NaN        NaN\n",
            "1    2      bl   NaN  NaN   18.67   NaN        1.0\n",
            "2    2    init  23.0  2.5   28.67  17.0        2.0\n",
            "3    2     m06  28.0  0.0   19.67   NaN        1.0\n",
            "4    2     m36  29.0  0.0   20.00   NaN        1.0\n",
            "Final shape: (18162, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load your final merged dataset\n",
        "df = pd.read_csv(\"Final_Merged_Data.csv\")\n",
        "\n",
        "# 1Ô∏è‚É£ Remove MOCA column\n",
        "df = df.drop(columns=[\"MOCA\"])\n",
        "\n",
        "# 2Ô∏è‚É£ Keep only rows where ALL remaining columns are filled\n",
        "df_clean = df.dropna()\n",
        "\n",
        "# 3Ô∏è‚É£ Reset index (optional but good practice)\n",
        "df_clean = df_clean.reset_index(drop=True)\n",
        "\n",
        "# 4Ô∏è‚É£ Check result\n",
        "print(\"Shape before cleaning:\", df.shape)\n",
        "print(\"Shape after cleaning:\", df_clean.shape)\n",
        "\n",
        "print(df_clean.head())\n",
        "\n",
        "# 5Ô∏è‚É£ Save clean dataset\n",
        "df_clean.to_csv(\"Final_Cleaned_Data.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAexy4cLeRAQ",
        "outputId": "9cb54195-f564-45b6-9155-843048030ad6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape before cleaning: (18162, 6)\n",
            "Shape after cleaning: (9420, 6)\n",
            "   RID VISCODE  MMSE  CDR  ADAS13  DIAGNOSIS\n",
            "0    2    init  23.0  2.5   28.67        2.0\n",
            "1    2     m06  28.0  0.0   19.67        1.0\n",
            "2    2     m36  29.0  0.0   20.00        1.0\n",
            "3    2     m60  28.0  0.0   22.67        1.0\n",
            "4    2     v06  23.0  0.0   21.00        1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**After Added Scores**"
      ],
      "metadata": {
        "id": "2W_v6stuzENG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "faq = faq[['RID', 'VISCODE', 'FAQTOTAL']]\n",
        "neuro = neuro[['RID', 'VISCODE',\n",
        "               'LDELTOTAL',\n",
        "               'AVTOT1','AVTOT2','AVTOT3','AVTOT4','AVTOT5',\n",
        "               'AVDELTOT']]\n",
        "uw = uw[['RID', 'VISCODE', 'ADNI_MEM', 'ADNI_EF']]\n",
        "ecog = ecog[['RID', 'VISCODE', 'EcogSPTotal']]\n"
      ],
      "metadata": {
        "id": "IT-Vu2xCzDVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start from your cleaned dataset\n",
        "df = pd.read_csv(\"Final_Cleaned_Data.csv\")\n",
        "\n",
        "# Merge FAQ\n",
        "df = df.merge(faq, on=['RID','VISCODE'], how='left')\n",
        "\n",
        "# Merge Neuropsych\n",
        "df = df.merge(neuro, on=['RID','VISCODE'], how='left')\n",
        "\n",
        "# Merge UW composite\n",
        "df = df.merge(uw, on=['RID','VISCODE'], how='left')\n",
        "\n",
        "# Merge Ecog\n",
        "# df = df.merge(ecog, on=['RID','VISCODE'], how='left')\n",
        "df = df.dropna()\n",
        "# Remove rows with missing values\n",
        "print(\"Shape after cleaning:\", df.shape)\n",
        "\n",
        "df.to_csv(\"Final_DL_Strong_Dataset.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgF4iFsCzbjl",
        "outputId": "736eb114-fc8b-41ac-c7e5-763941b36ed4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape after cleaning: (6652, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 1Ô∏è‚É£ Import Libraries\n",
        "# ============================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# 2Ô∏è‚É£ Load Dataset\n",
        "# ============================================\n",
        "df = pd.read_csv(\"Final_DL_Strong_Dataset.csv\")\n",
        "\n",
        "# Remove non-feature columns\n",
        "df = df.drop(columns=[\"RID\", \"VISCODE\"])\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# 3Ô∏è‚É£ FIX ADNI DIAGNOSIS LABELS\n",
        "# ADNI uses:\n",
        "# 1 = CN\n",
        "# 2 = MCI\n",
        "# 3 = AD\n",
        "# We must convert to:\n",
        "# 0 = CN\n",
        "# 1 = MCI\n",
        "# 2 = AD\n",
        "# ============================================\n",
        "\n",
        "df['DIAGNOSIS'] = df['DIAGNOSIS'].map({\n",
        "    1: 0,\n",
        "    2: 1,\n",
        "    3: 2\n",
        "})\n",
        "\n",
        "print(\"Class Distribution:\")\n",
        "print(df['DIAGNOSIS'].value_counts())\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# 4Ô∏è‚É£ Separate Features and Target\n",
        "# ============================================\n",
        "X = df.drop(columns=[\"DIAGNOSIS\"])\n",
        "y = df[\"DIAGNOSIS\"]\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# 5Ô∏è‚É£ Train-Test Split (Stratified)\n",
        "# ============================================\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# 6Ô∏è‚É£ Normalize Features (Correct Way)\n",
        "# Fit ONLY on training data\n",
        "# ============================================\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# 7Ô∏è‚É£ Convert to PyTorch Tensors\n",
        "# ============================================\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# 8Ô∏è‚É£ Define Neural Network\n",
        "# ============================================\n",
        "class AlzheimerNN(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(AlzheimerNN, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_size, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(32, 16),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Linear(16, 3)  # 3 output classes (CN, MCI, AD)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "# Initialize model\n",
        "input_size = X_train.shape[1]\n",
        "model = AlzheimerNN(input_size)\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "\n",
        "# Manually calculated weights\n",
        "class_weights = torch.tensor([0.89, 0.81, 1.58], dtype=torch.float32)\n",
        "\n",
        "# Move to device if using GPU\n",
        "# class_weights = class_weights.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "# ============================================\n",
        "# 9Ô∏è‚É£ Loss Function & Optimizer\n",
        "# ============================================\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# üîü Training Loop\n",
        "# ============================================\n",
        "num_epochs = 500\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_train_tensor)\n",
        "    loss = criterion(outputs, y_train_tensor)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# 1Ô∏è‚É£1Ô∏è‚É£ Evaluation\n",
        "# ============================================\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(X_test_tensor)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    accuracy = (predicted == y_test_tensor).sum().item() / y_test_tensor.size(0)\n",
        "\n",
        "print(\"\\nTest Accuracy:\", round(accuracy * 100, 2), \"%\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_tensor, predicted))\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test_tensor, predicted))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXTCJIME6Ed4",
        "outputId": "3e6a2be5-daf9-49ac-9d68-173c7bba5c7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Distribution:\n",
            "DIAGNOSIS\n",
            "1    2743\n",
            "0    2504\n",
            "2    1405\n",
            "Name: count, dtype: int64\n",
            "Epoch [10/500], Loss: 0.8883\n",
            "Epoch [20/500], Loss: 0.7585\n",
            "Epoch [30/500], Loss: 0.6602\n",
            "Epoch [40/500], Loss: 0.5846\n",
            "Epoch [50/500], Loss: 0.5275\n",
            "Epoch [60/500], Loss: 0.4920\n",
            "Epoch [70/500], Loss: 0.4664\n",
            "Epoch [80/500], Loss: 0.4478\n",
            "Epoch [90/500], Loss: 0.4426\n",
            "Epoch [100/500], Loss: 0.4197\n",
            "Epoch [110/500], Loss: 0.4120\n",
            "Epoch [120/500], Loss: 0.4105\n",
            "Epoch [130/500], Loss: 0.3983\n",
            "Epoch [140/500], Loss: 0.3978\n",
            "Epoch [150/500], Loss: 0.3861\n",
            "Epoch [160/500], Loss: 0.3756\n",
            "Epoch [170/500], Loss: 0.3765\n",
            "Epoch [180/500], Loss: 0.3678\n",
            "Epoch [190/500], Loss: 0.3694\n",
            "Epoch [200/500], Loss: 0.3671\n",
            "Epoch [210/500], Loss: 0.3616\n",
            "Epoch [220/500], Loss: 0.3636\n",
            "Epoch [230/500], Loss: 0.3674\n",
            "Epoch [240/500], Loss: 0.3588\n",
            "Epoch [250/500], Loss: 0.3593\n",
            "Epoch [260/500], Loss: 0.3606\n",
            "Epoch [270/500], Loss: 0.3519\n",
            "Epoch [280/500], Loss: 0.3582\n",
            "Epoch [290/500], Loss: 0.3530\n",
            "Epoch [300/500], Loss: 0.3472\n",
            "Epoch [310/500], Loss: 0.3560\n",
            "Epoch [320/500], Loss: 0.3510\n",
            "Epoch [330/500], Loss: 0.3542\n",
            "Epoch [340/500], Loss: 0.3551\n",
            "Epoch [350/500], Loss: 0.3483\n",
            "Epoch [360/500], Loss: 0.3527\n",
            "Epoch [370/500], Loss: 0.3464\n",
            "Epoch [380/500], Loss: 0.3473\n",
            "Epoch [390/500], Loss: 0.3514\n",
            "Epoch [400/500], Loss: 0.3477\n",
            "Epoch [410/500], Loss: 0.3428\n",
            "Epoch [420/500], Loss: 0.3439\n",
            "Epoch [430/500], Loss: 0.3505\n",
            "Epoch [440/500], Loss: 0.3432\n",
            "Epoch [450/500], Loss: 0.3415\n",
            "Epoch [460/500], Loss: 0.3415\n",
            "Epoch [470/500], Loss: 0.3406\n",
            "Epoch [480/500], Loss: 0.3406\n",
            "Epoch [490/500], Loss: 0.3402\n",
            "Epoch [500/500], Loss: 0.3401\n",
            "\n",
            "Test Accuracy: 85.8 %\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.89      0.90       501\n",
            "           1       0.85      0.79      0.82       549\n",
            "           2       0.79      0.93      0.85       281\n",
            "\n",
            "    accuracy                           0.86      1331\n",
            "   macro avg       0.85      0.87      0.86      1331\n",
            "weighted avg       0.86      0.86      0.86      1331\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[447  54   0]\n",
            " [ 46 435  68]\n",
            " [  0  21 260]]\n"
          ]
        }
      ]
    }
  ]
}